{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# epann\n",
    "\n",
    "Evolutionary Plastic Artificial Neural Networks\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Back to [Part 2: Simulating Agents that Learn](02agentsenvs.ipynb)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroevolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If we would like to evolve a population of our example agents on the task described in **Part 2**, it is important that we have a stable representation of an artificial neural network. With that representation, it will be possible to have two agent's reproduce, as well as mutate a single genome with each generation. \n",
    "\n",
    "Within the field of neuroevolution, there are generally two different types of neural network representations we can choose as our agent genome: *direct* and *indirect encodings*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Direct Encodings\n",
    "\n",
    "Since we need to find a representation for an agent in our population described in **Part 2**, let's start with the simplest agent of that kind: a fully-connected neural network with 3 output nodes, 6 input nodes, and no hidden nodes. (**Figure 3.1**)\n",
    "\n",
    "##### Figure 3.1 - Simplest Agent Neural Network\n",
    "\n",
    "![Figure 3.1](figures/simplestnet.png)\n",
    "\n",
    "A directly encoded genome contains a one-to-one relationship between the parameters that describe the neural network and the number of genes in the associated agent genome. \n",
    "\n",
    "For example, an agent with the network shown in **Figure 3.1** has 18 unique weights, and therefore a direct encoding of that agent will require at least 18 values. It may additionally require information about the number of inputs, outputs, the activation functions used in those outputs, as well parameters that influence its learning within the environment. \n",
    "\n",
    "For the purpose of our very simple task, 18 weight values is not very much. It would not be difficult to apply standard gradient-based learning to find the appropriate parameters for this model. If we did want to represent the network with a genome, 18 genes for each of the weights is relatively small, and we don't run into many problems performing reproduction on mutation on it. \n",
    "\n",
    "A direct encoding that will turn out to be essential to the approach of **epann** is known as NeuroEvolution of Augmenting Topologies, or NEAT. In the original paper that described the NEAT algorithm, a simple controller much like our example was described genetically as containing two separate lists to describe its neural network phenotype. (**Figure 3.2**)\n",
    "\n",
    "A neural network is first described by its *node genome* (**Figure 3.2(a)**). The node genome is a list of each node in the agent's neural network, along with some characteristics about each node. Nodes have a *type*, which distinguishes them as being an input, output or hidden node. Individual nodes also have unique *activation functions*, that determine the function applied to its summed inputs. \n",
    "\n",
    "An agent also has a *connection genome* (**Figure 3.2(b)**). The connection genome is a list of each connection in the agent's neural network, and it also has a list of attributes that describe them. They have an identification number (or, as will be called later, *innovation numbers*), a description of the nodes that start and end that connection (soon to be referred to as a connection's *out node* and *in node*, respectively), and a weight. Connection genes also contain a final binary attribute called the *enable bit*, that determines whether or not a connection described in the connection genome will actually be expressed in the final agent phenotype.  \n",
    "\n",
    "##### Figure 3.2 - Direct Encoding in the original NEAT algorithm\n",
    "###### Node and connection numbering maintain Python's 0-based indexing left to right.\n",
    "\n",
    "![Figure 3.2](figures/neat_genomes.png)\n",
    "\n",
    "However, a direct encoding present difficulty as a general purpose representation for neural networks. Direct encodings will also require as many genes as there are parameters for more complex models, such as modern benchmark convolutional neural networks, which may contain over a million parameters. Using a genetic algorithm in a space that large will be difficult, and it is likely that candidate solutions will bounce around the space without converging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indirect Encodings  \n",
    "\n",
    "We do not see an analog of direct encoding in the genomes of biological organisms. Organisms tend to have genotypes with less information than the phenotypes they generate. The number of genes in a genome is far less than it would take to encode individual connections in its nervous system, let alone features of every cell in its body. \n",
    "\n",
    "Instead, it seems that the emergence of life has settled on genetic representations that are far more complex. Genes are associated with the development of many different systems within an organism. As a result, a mutation in a particular gene can have widespread effects. \n",
    "\n",
    "Indirect encodings can also change the search space we are exploring during our optimization. \n",
    "\n",
    "In the field of neuroevolution, different indirect encoding frameworks have been suggested to fill this need. In **epann** our indirect encodings will focus on representing neural networks with genomes that are themselves neural networks called Compositional Pattern Producing Networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Move on to [Part 4: Compositional Pattern Producing Networks](04cppns.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}