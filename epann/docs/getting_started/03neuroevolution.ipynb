{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epann\n",
    "\n",
    "##### Evolutionary Plastic Artificial Neural Networks\n",
    "\n",
    "\n",
    "Back to [Part 2: Simulating Agents that Learn](02agentsenvs.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroevolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If we would like to evolve a population of our example agents on the task described in **Part 2**, it is important that we have a stable representation of an artificial neural network. With that representation, it will be possible to have two agent's reproduce, as well as mutate a single genome with each generation. \n",
    "\n",
    "Within the field of neuroevolution, there are generally two different types of neural network representations we can choose as our agent genome: *direct* and *indirect encodings*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Direct Encodings\n",
    "\n",
    "Since we need to find a representation for an agent in our population described in **Part 2**, let's start with the simplest agent of that kind: a fully-connected neural network with 3 output nodes, 6 input nodes, and no hidden nodes. (**Figure 3.1**)\n",
    "\n",
    "##### Figure 3.1 - Simplest Agent Neural Network\n",
    "\n",
    "![Figure 3.1](figures/simplestnet.png)\n",
    "\n",
    "A directly encoded genome contains a one-to-one relationship between the parameters that describe the neural network and the number of genes in the associated agent genome. \n",
    "\n",
    "For example, an agent with the network shown in **Figure 3.1** has 18 unique weights, and therefore a direct encoding of that agent will require at least 18 values. It may additionally require information about the number of inputs, outputs, the activation functions used in those outputs, as well parameters that influence its learning within the environment. \n",
    "\n",
    "For the purpose of our very simple task, 18 weight values is not very much. It would not be difficult to apply standard gradient-based learning to find the appropriate parameters for this model. If we did want to represent the network with a genome, 18 genes for each of the weights is relatively small, and we don't run into many problems performing reproduction on mutation on it. \n",
    "\n",
    "However, a direct encoding present difficulty as a general purpose representation for neural networks. Direct encodings will also require as many genes as there are parameters for more complex models, such as modern benchmark convolutional neural networks, which may contain over a million parameters. Using a genetic algorithm in a space that large will be difficult, and it is likely that candidate solutions will bounce around the space without converging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indirect Encodings  \n",
    "\n",
    "We do not see an analog of direct encoding in the genomes of biological organisms. Organisms tend to have genotypes with less information than the phenotypes they encode. The number of genes in a genome is far less than it would take to encode individual connections in its nervous system, let alone features of every cell in its body. \n",
    "\n",
    "Instead, it seems that the emergence of life has settled on genetic representations that are far more complex. Genes are associated with the development of many different systems within an organism. As a result, a mutation in a particular gene can have widespread effects. \n",
    "\n",
    "Indirect encodings can also change the search space we are exploring during our optimization. \n",
    "\n",
    "In the field of neuroevolution, different indirect encoding frameworks have been suggested to fill this need. In **epann** our indirect encodings will focus on representing neural networks with genomes that are themselves neural networks called Compositional Pattern Producing Networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move on to [Part 4: Compositional Pattern Producing Networks](04cppns.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
